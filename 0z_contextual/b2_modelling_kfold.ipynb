{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2014-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2014-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2013-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2014-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2014-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608593</th>\n",
       "      <td>119664</td>\n",
       "      <td>5039</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608594</th>\n",
       "      <td>56277</td>\n",
       "      <td>5039</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-11-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608595</th>\n",
       "      <td>265320</td>\n",
       "      <td>5039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-08-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608596</th>\n",
       "      <td>161722</td>\n",
       "      <td>5039</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608597</th>\n",
       "      <td>78454</td>\n",
       "      <td>5039</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-07-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608598 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  prod_id  rating  label        date\n",
       "0          5044        0     1.0     -1  2014-11-16\n",
       "1          5045        0     1.0     -1  2014-09-08\n",
       "2          5046        0     3.0     -1  2013-10-06\n",
       "3          5047        0     5.0     -1  2014-11-30\n",
       "4          5048        0     5.0     -1  2014-08-28\n",
       "...         ...      ...     ...    ...         ...\n",
       "608593   119664     5039     4.0      1  2013-01-20\n",
       "608594    56277     5039     2.0      1  2012-11-12\n",
       "608595   265320     5039     1.0      1  2012-08-22\n",
       "608596   161722     5039     4.0      1  2011-05-11\n",
       "608597    78454     5039     4.0      1  2010-07-17\n",
       "\n",
       "[608598 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../00_dataset/YelpZip/metadata', \n",
    "                 sep='\\t',\n",
    "                 header=None,\n",
    "                 names=[\"user_id\", \"prod_id\", \"rating\", \"label\", \"date\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Pre-processing\n",
    "Minimal cleanup because feature engineering will be using and converting date values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    0\n",
       "prod_id    0\n",
       "rating     0\n",
       "label      0\n",
       "date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].replace(-1, 0)\n",
    "y = df['label']\n",
    "X = df.drop('label', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train: (426018, 4)\n",
      "X_test: (182580, 4)\n",
      "y_train: (426018,)\n",
      "y_test: (182580,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "X_train: {X_train.shape}\n",
    "X_test: {X_test.shape}\n",
    "y_train: {y_train.shape}\n",
    "y_test: {y_test.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: LogisticRegression\n",
      "NN: MLPClassifier\n",
      "KNN: KNeighborsClassifier\n",
      "DT: DecisionTreeClassifier\n",
      "RF: RandomForestClassifier\n",
      "AB: AdaBoostClassifier\n",
      "XGB: XGBClassifier\n",
      "NB: GaussianNB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier  # Boosting\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "models = {\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"NN\": MLPClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"AB\": AdaBoostClassifier(),\n",
    "    \"XGB\": XGBClassifier(),\n",
    "    \"NB\": GaussianNB(),\n",
    "}\n",
    "\n",
    "# Example usage: print model names\n",
    "for category, model in models.items():\n",
    "    print(f\"{category}: {model.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['date'] = pd.to_datetime(X_train['date']).astype('int64') // 10**9\n",
    "# X_test['date'] = pd.to_datetime(X_test['date']).astype('int64') // 10**9\n",
    "# X_train = X_train.drop(columns=[\"user_id\", \"prod_id\"])\n",
    "# X_test = X_test.drop(columns=[\"user_id\", \"prod_id\"])\n",
    "\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: LR ===\n",
      "Accuracy: 0.557, Precision: 0.972, Recall: 0.505, F1: 0.664\n",
      "Balanced Accuracy: 0.705\n",
      "=== Model: NN ===\n",
      "Accuracy: 0.692, Precision: 0.920, Recall: 0.707, F1: 0.799\n",
      "Balanced Accuracy: 0.653\n",
      "=== Model: KNN ===\n",
      "Accuracy: 0.729, Precision: 0.898, Recall: 0.777, F1: 0.833\n",
      "Balanced Accuracy: 0.598\n",
      "=== Model: DT ===\n",
      "Accuracy: 0.792, Precision: 0.885, Recall: 0.874, F1: 0.880\n",
      "Balanced Accuracy: 0.565\n",
      "=== Model: RF ===\n",
      "Accuracy: 0.837, Precision: 0.880, Recall: 0.940, F1: 0.909\n",
      "Balanced Accuracy: 0.549\n",
      "=== Model: AB ===\n",
      "Accuracy: 0.724, Precision: 0.894, Recall: 0.773, F1: 0.829\n",
      "Balanced Accuracy: 0.587\n",
      "=== Model: XGB ===\n",
      "Accuracy: 0.626, Precision: 0.972, Recall: 0.586, F1: 0.731\n",
      "Balanced Accuracy: 0.738\n",
      "=== Model: NB ===\n",
      "Accuracy: 0.578, Precision: 0.959, Recall: 0.537, F1: 0.689\n",
      "Balanced Accuracy: 0.693\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from FeatureEngineer import CombinedEngineer\n",
    "from SmoteTransformer import SMOTETransformer\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"=== Model: {name} ===\")\n",
    "    # Define the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('feature_engineering', CombinedEngineer(drop_columns=[])),  # drop_columns = [] or None for no features dropped\n",
    "        ('scaler', StandardScaler()),  # scaling\n",
    "        ('smote', SMOTETransformer(sampling_strategy='auto', random_state=42)),  # SMOTE\n",
    "        ('classifier', model)  # Classifier\n",
    "    ])\n",
    "\n",
    "    # Fit and evaluate the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    print(f\"Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "    # Balanced accuracy\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"Balanced Accuracy: {balanced_acc:.3f}\")\n",
    "\n",
    "    # MCC\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    # PR-AUC\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)\n",
    "\n",
    "\n",
    "    # ROC-AUC for both classes (Class 0 and Class 1)\n",
    "    roc_auc_0 = roc_auc_score(y_test, y_pred_proba[:, 0])  # ROC-AUC for Class 0 (minority class)\n",
    "    roc_auc_1 = roc_auc_score(y_test, y_pred_proba[:, 1])  # ROC-AUC for Class 1 (majority class)\n",
    "\n",
    "    # PR-AUC for both classes\n",
    "    precision_0, recall_0, _ = precision_recall_curve(y_test, y_pred_proba[:, 0])  # For Class 0\n",
    "    pr_auc_0 = auc(recall_0, precision_0)\n",
    "\n",
    "    precision_1, recall_1, _ = precision_recall_curve(y_test, y_pred_proba[:, 1])  # For Class 1\n",
    "    pr_auc_1 = auc(recall_1, precision_1)\n",
    "\n",
    "    # print(f\"Balanced Accuracy: {balanced_acc:.3f}\")\n",
    "    # print(f\"Matthews Correlation Coefficient: {mcc:.3f}\")\n",
    "    # print(f\"PR-AUC for class 0: {pr_auc_0:.3f}\")\n",
    "    # print(f\"PR-AUC for class 1: {pr_auc_1:.3f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": f\"{name}_FESS\",\n",
    "        \"Accuracy\": f\"{accuracy:.4f}\",\n",
    "        \"Precision\": f\"{precision:.4f}\",\n",
    "        \"Recall\": f\"{recall:.4f}\",\n",
    "        \"F1 Score\": f\"{f1:.4f}\",\n",
    "        \"Balanced Accuracy\": f\"{balanced_acc:.4f}\",\n",
    "        \"MCC\": f\"{mcc:.4f}\",\n",
    "        \"PR-AUC_0\": f\"{pr_auc_0:.4f}\",\n",
    "        \"PR-AUC_1\": f\"{pr_auc_1:.4f}\",\n",
    "        \"ROC-AUC_0\": f\"{roc_auc_0:.4f}\",\n",
    "        \"ROC-AUC_1\": f\"{roc_auc_1:.4f}\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Evaluation Results ===\n",
      "      Model Accuracy Precision  Recall F1 Score Balanced Accuracy     MCC  \\\n",
      "5   AB_FESS   0.7240    0.8944  0.7733   0.8294            0.5870  0.1361   \n",
      "3   DT_FESS   0.7923    0.8852  0.8740   0.8796            0.5651  0.1258   \n",
      "2  KNN_FESS   0.7294    0.8976  0.7768   0.8328            0.5975  0.1528   \n",
      "0   LR_FESS   0.5575    0.9720  0.5046   0.6643            0.7045  0.2785   \n",
      "7   NB_FESS   0.5784    0.9588  0.5372   0.6886            0.6929  0.2615   \n",
      "1   NN_FESS   0.6923    0.9205  0.7065   0.7994            0.6529  0.2196   \n",
      "4   RF_FESS   0.8370    0.8800  0.9405   0.9092            0.5492  0.1285   \n",
      "6  XGB_FESS   0.6260    0.9722  0.5857   0.7310            0.7380  0.3228   \n",
      "\n",
      "  PR-AUC_0 PR-AUC_1 ROC-AUC_0 ROC-AUC_1  \n",
      "5   0.8055   0.9514    0.2743    0.7257  \n",
      "3   0.8240   0.9343    0.4350    0.5650  \n",
      "2   0.8165   0.9343    0.3565    0.6435  \n",
      "0   0.7851   0.9550    0.2463    0.7537  \n",
      "7   0.7900   0.9524    0.2589    0.7411  \n",
      "1   0.8034   0.9482    0.2761    0.7239  \n",
      "4   0.7790   0.9603    0.2297    0.7703  \n",
      "6   0.7641   0.9656    0.1984    0.8016  \n"
     ]
    }
   ],
   "source": [
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort the results by \"Model\" alphabetically\n",
    "results_df = results_df.sort_values(by=\"Model\")\n",
    "\n",
    "# Display the results table\n",
    "print(\"\\n=== Model Evaluation Results ===\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>MCC</th>\n",
       "      <th>PR-AUC_0</th>\n",
       "      <th>PR-AUC_1</th>\n",
       "      <th>ROC-AUC_0</th>\n",
       "      <th>ROC-AUC_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AB_FESS</td>\n",
       "      <td>0.7240</td>\n",
       "      <td>0.8944</td>\n",
       "      <td>0.7733</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.8055</td>\n",
       "      <td>0.9514</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.7257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT_FESS</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.5651</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>0.9343</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>0.5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN_FESS</td>\n",
       "      <td>0.7294</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.7768</td>\n",
       "      <td>0.8328</td>\n",
       "      <td>0.5975</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.8165</td>\n",
       "      <td>0.9343</td>\n",
       "      <td>0.3565</td>\n",
       "      <td>0.6435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_FESS</td>\n",
       "      <td>0.5575</td>\n",
       "      <td>0.9720</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.6643</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.2785</td>\n",
       "      <td>0.7851</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>0.7537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB_FESS</td>\n",
       "      <td>0.5784</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.2615</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>0.7411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN_FESS</td>\n",
       "      <td>0.6923</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.7065</td>\n",
       "      <td>0.7994</td>\n",
       "      <td>0.6529</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.8034</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.2761</td>\n",
       "      <td>0.7239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_FESS</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>0.7790</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>0.2297</td>\n",
       "      <td>0.7703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB_FESS</td>\n",
       "      <td>0.6260</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>0.3228</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.8016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model Accuracy Precision  Recall F1 Score Balanced Accuracy     MCC  \\\n",
       "5   AB_FESS   0.7240    0.8944  0.7733   0.8294            0.5870  0.1361   \n",
       "3   DT_FESS   0.7923    0.8852  0.8740   0.8796            0.5651  0.1258   \n",
       "2  KNN_FESS   0.7294    0.8976  0.7768   0.8328            0.5975  0.1528   \n",
       "0   LR_FESS   0.5575    0.9720  0.5046   0.6643            0.7045  0.2785   \n",
       "7   NB_FESS   0.5784    0.9588  0.5372   0.6886            0.6929  0.2615   \n",
       "1   NN_FESS   0.6923    0.9205  0.7065   0.7994            0.6529  0.2196   \n",
       "4   RF_FESS   0.8370    0.8800  0.9405   0.9092            0.5492  0.1285   \n",
       "6  XGB_FESS   0.6260    0.9722  0.5857   0.7310            0.7380  0.3228   \n",
       "\n",
       "  PR-AUC_0 PR-AUC_1 ROC-AUC_0 ROC-AUC_1  \n",
       "5   0.8055   0.9514    0.2743    0.7257  \n",
       "3   0.8240   0.9343    0.4350    0.5650  \n",
       "2   0.8165   0.9343    0.3565    0.6435  \n",
       "0   0.7851   0.9550    0.2463    0.7537  \n",
       "7   0.7900   0.9524    0.2589    0.7411  \n",
       "1   0.8034   0.9482    0.2761    0.7239  \n",
       "4   0.7790   0.9603    0.2297    0.7703  \n",
       "6   0.7641   0.9656    0.1984    0.8016  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"b2_results_RFE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Access individual steps in the pipeline\n",
    "# feature_engineering_step = pipeline.named_steps['feature_engineering']\n",
    "scaler_step = pipeline.named_steps['scaler']\n",
    "smote_step = pipeline.named_steps['smote']\n",
    "classifier_step = pipeline.named_steps['classifier']\n",
    "\n",
    "X_engineered = X_train\n",
    "# 2. Check the transformed data at each step\n",
    "# For training data\n",
    "# X_engineered = feature_engineering_step.transform(X_train)\n",
    "X_scaled = scaler_step.transform(X_engineered)\n",
    "X_resampled, y_resampled = smote_step.fit_resample(X_scaled, y_train)\n",
    "\n",
    "# 3. Check shapes to understand SMOTE's effect\n",
    "print(f\"Original X_train shape: {X_train.shape}\")\n",
    "print(f\"After engineering: {X_engineered.shape}\")\n",
    "print(f\"After scaling: {X_scaled.shape}\")\n",
    "print(f\"After SMOTE: {X_resampled.shape}, y_resampled: {y_resampled.shape}\")\n",
    "\n",
    "# 4. Compare class distributions\n",
    "from collections import Counter\n",
    "print(f\"Original class distribution: {Counter(y_train)}\")\n",
    "print(f\"Resampled class distribution: {Counter(y_resampled)}\")\n",
    "\n",
    "# 5. Extract feature importances (if classifier supports it)\n",
    "if hasattr(classifier_step, 'feature_importances_'):\n",
    "    importances = classifier_step.feature_importances_\n",
    "    print(importances)\n",
    "\n",
    "    # Print top features\n",
    "elif hasattr(classifier_step, 'coef_'):\n",
    "    importances = classifier_step.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# checking versions (sync with kaggle if using)\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "print(\"Python Version:\", sys.version)\n",
    "print(\"NumPy Version:\", np.__version__)\n",
    "print(\"Pandas Version:\", pd.__version__)\n",
    "print(\"Scikit-Learn Version:\", sklearn.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 21,
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 22,
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2014-11-16</td>\n",
       "      <td>Drinks were bad, the hot chocolate was watered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2014-09-08</td>\n",
       "      <td>This was the worst experience I've ever had a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>This is located on the site of the old Spruce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2014-11-30</td>\n",
       "      <td>I enjoyed coffee and breakfast twice at Toast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2014-08-28</td>\n",
       "      <td>I love Toast! The food choices are fantastic -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608593</th>\n",
       "      <td>119664</td>\n",
       "      <td>5039</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-20</td>\n",
       "      <td>When I first moved to the area I must say I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608594</th>\n",
       "      <td>56277</td>\n",
       "      <td>5039</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-11-12</td>\n",
       "      <td>Kind of pricey. I guess I expected a ridiculou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608595</th>\n",
       "      <td>265320</td>\n",
       "      <td>5039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-08-22</td>\n",
       "      <td>Stopped by this restaurant yesterday, we just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608596</th>\n",
       "      <td>161722</td>\n",
       "      <td>5039</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-05-11</td>\n",
       "      <td>Finally checked out The Best Subs in Claremont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608597</th>\n",
       "      <td>78454</td>\n",
       "      <td>5039</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-07-17</td>\n",
       "      <td>Just got me some \"Best Subs\" and I gotta say, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608458 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  prod_id  rating  label        date  \\\n",
       "0          5044        0     1.0     -1  2014-11-16   \n",
       "1          5045        0     1.0     -1  2014-09-08   \n",
       "2          5046        0     3.0     -1  2013-10-06   \n",
       "3          5047        0     5.0     -1  2014-11-30   \n",
       "4          5048        0     5.0     -1  2014-08-28   \n",
       "...         ...      ...     ...    ...         ...   \n",
       "608593   119664     5039     4.0      1  2013-01-20   \n",
       "608594    56277     5039     2.0      1  2012-11-12   \n",
       "608595   265320     5039     1.0      1  2012-08-22   \n",
       "608596   161722     5039     4.0      1  2011-05-11   \n",
       "608597    78454     5039     4.0      1  2010-07-17   \n",
       "\n",
       "                                                   review  \n",
       "0       Drinks were bad, the hot chocolate was watered...  \n",
       "1       This was the worst experience I've ever had a ...  \n",
       "2       This is located on the site of the old Spruce ...  \n",
       "3       I enjoyed coffee and breakfast twice at Toast ...  \n",
       "4       I love Toast! The food choices are fantastic -...  \n",
       "...                                                   ...  \n",
       "608593  When I first moved to the area I must say I wa...  \n",
       "608594  Kind of pricey. I guess I expected a ridiculou...  \n",
       "608595  Stopped by this restaurant yesterday, we just ...  \n",
       "608596  Finally checked out The Best Subs in Claremont...  \n",
       "608597  Just got me some \"Best Subs\" and I gotta say, ...  \n",
       "\n",
       "[608458 rows x 6 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 2,
=======
     "execution_count": 22,
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../00_dataset/YelpZip/metadata', \n",
    "                 sep='\\t',\n",
    "                 header=None,\n",
    "                 names=[\"user_id\", \"prod_id\", \"rating\", \"label\", \"date\"])\n",
    "reviews_df = pd.read_csv('../00_dataset/YelpZip/reviewContent',\n",
    "                sep='\\t',\n",
    "                header=None,\n",
    "                names=['user_id', 'prod_id', 'date', 'review'])\n",
    "\n",
    "df = df.merge(reviews_df,\n",
    "              left_on=['user_id', 'prod_id', 'date'],\n",
    "              right_on=['user_id', 'prod_id', 'date'],\n",
    "              how='left')\n",
    "df = df.dropna(subset=['review'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Pre-processing\n",
    "Minimal cleanup because feature engineering will be using and converting date values."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 23,
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    0\n",
       "prod_id    0\n",
       "rating     0\n",
       "label      0\n",
       "date       0\n",
       "review     0\n",
       "dtype: int64"
      ]
     },
<<<<<<< HEAD
     "execution_count": 3,
=======
     "execution_count": 23,
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 24,
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].replace({1: 0, -1: 1})\n",
    "y = df['label']\n",
    "X = df.drop('label', axis=1)\n",
    "X_train, X_test, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 25,
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train: (425920, 5)\n",
      "X_validation: (60846, 5)\n",
      "X_test: (121692, 5)\n",
      "y_train: (425920,)\n",
      "y_validation: (60846,)\n",
      "y_test: (60846,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "X_train: {X_train.shape}\n",
    "X_validation: {X_val.shape}\n",
    "X_test: {X_test.shape}\n",
    "y_train: {y_train.shape}\n",
    "y_validation: {y_val.shape}\n",
    "y_test: {y_val.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 26,
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: LogisticRegression\n",
      "NN: MLPClassifier\n",
      "KNN: KNeighborsClassifier\n",
      "DT: DecisionTreeClassifier\n",
      "RF: RandomForestClassifier\n",
      "AB: AdaBoostClassifier\n",
      "XGB: XGBClassifier\n",
      "NB: GaussianNB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier  # Boosting\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "models = {\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"NN\": MLPClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"AB\": AdaBoostClassifier(),\n",
    "    \"XGB\": XGBClassifier(),\n",
    "    \"NB\": GaussianNB(),\n",
    "}\n",
    "\n",
    "# Example usage: print model names\n",
    "for category, model in models.items():\n",
    "    print(f\"{category}: {model.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pipeline"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 27,
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train['date'] = pd.to_datetime(X_train['date']).astype('int64') // 10**9\n",
    "# X_test['date'] = pd.to_datetime(X_test['date']).astype('int64') // 10**9\n",
    "# X_train = X_train.drop(columns=[\"user_id\", \"prod_id\"])\n",
    "# X_test = X_test.drop(columns=[\"user_id\", \"prod_id\"])\n",
    "\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": null,
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: LR ===\n",
<<<<<<< HEAD
      "Accuracy: 0.681, Precision: 0.146, Recall: 0.293, F1: 0.195\n",
      "Balanced Accuracy: 0.516\n",
      "=== Model: NN ===\n",
      "Accuracy: 0.537, Precision: 0.174, Recall: 0.669, F1: 0.277\n",
      "Balanced Accuracy: 0.593\n",
      "=== Model: KNN ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.868, Precision: 0.000, Recall: 0.000, F1: 0.000\n",
      "Balanced Accuracy: 0.500\n",
      "=== Model: DT ===\n",
      "Accuracy: 0.537, Precision: 0.174, Recall: 0.669, F1: 0.277\n",
      "Balanced Accuracy: 0.593\n",
      "=== Model: RF ===\n",
      "Accuracy: 0.537, Precision: 0.174, Recall: 0.669, F1: 0.277\n",
      "Balanced Accuracy: 0.593\n",
      "=== Model: AB ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.537, Precision: 0.174, Recall: 0.669, F1: 0.277\n",
      "Balanced Accuracy: 0.593\n",
      "=== Model: XGB ===\n",
      "Accuracy: 0.537, Precision: 0.174, Recall: 0.669, F1: 0.277\n",
      "Balanced Accuracy: 0.593\n",
      "=== Model: NB ===\n",
      "Accuracy: 0.797, Precision: 0.224, Recall: 0.218, F1: 0.221\n",
      "Balanced Accuracy: 0.551\n"
=======
      "Accuracy: 0.557, Precision: 0.972, Recall: 0.505, F1: 0.664\n",
      "Balanced Accuracy: 0.705\n",
      "=== Model: NN ===\n",
      "Accuracy: 0.692, Precision: 0.920, Recall: 0.707, F1: 0.799\n",
      "Balanced Accuracy: 0.653\n",
      "=== Model: KNN ===\n",
      "Accuracy: 0.729, Precision: 0.898, Recall: 0.777, F1: 0.833\n",
      "Balanced Accuracy: 0.598\n",
      "=== Model: DT ===\n",
      "Accuracy: 0.792, Precision: 0.885, Recall: 0.874, F1: 0.880\n",
      "Balanced Accuracy: 0.565\n",
      "=== Model: RF ===\n",
      "Accuracy: 0.837, Precision: 0.880, Recall: 0.940, F1: 0.909\n",
      "Balanced Accuracy: 0.549\n",
      "=== Model: AB ===\n",
      "Accuracy: 0.724, Precision: 0.894, Recall: 0.773, F1: 0.829\n",
      "Balanced Accuracy: 0.587\n",
      "=== Model: XGB ===\n",
      "Accuracy: 0.626, Precision: 0.972, Recall: 0.586, F1: 0.731\n",
      "Balanced Accuracy: 0.738\n",
      "=== Model: NB ===\n",
      "Accuracy: 0.578, Precision: 0.959, Recall: 0.537, F1: 0.689\n",
      "Balanced Accuracy: 0.693\n"
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from FeatureEngineer import CombinedEngineer\n",
    "from SmoteTransformer import SMOTETransformer\n",
    "\n",
<<<<<<< HEAD
    "prob_df = pd.DataFrame()\n",
    "test_on = [\"SS\"]\n",
=======
    "for name, model in models.items():\n",
    "    print(f\"=== Model: {name} ===\")\n",
    "    # Define the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('feature_engineering', CombinedEngineer(drop_columns=[])),  # drop_columns = [] or None for no features dropped\n",
    "        ('feature_engineering', CombinedEngineer(drop_columns=[])),  # drop_columns = [] or None for no features dropped\n",
    "        ('scaler', StandardScaler()),  # scaling\n",
    "        ('smote', SMOTETransformer(sampling_strategy='auto', random_state=42)),  # SMOTE\n",
    "        ('classifier', model)  # Classifier\n",
    "    ])\n",
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
    "\n",
    "for test in test_on:\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"=== Model: {name} ===\")\n",
    "        if test == \"FSS\":\n",
    "            pipeline = Pipeline([\n",
    "                ('feature_engineering', CombinedEngineer()),  # Feature engineering\n",
    "                ('scaler', StandardScaler()),  # scaling\n",
    "                ('smote', SMOTETransformer(sampling_strategy='auto', random_state=42)),  # SMOTE\n",
    "                ('classifier', model)  # Classifier\n",
    "            ])\n",
    "        elif test == \"SS\":\n",
    "            X_train['date'] = pd.to_datetime(X_train['date']).astype('int64') // 10**9\n",
    "            X_val['date'] = pd.to_datetime(X_val['date']).astype('int64') // 10**9\n",
    "            X_train = X_train.drop(columns=[\"user_id\", \"prod_id\", \"review\"], errors='ignore')\n",
    "            X_val = X_val.drop(columns=[\"user_id\", \"prod_id\", \"review\"], errors='ignore')\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                # ('feature_engineering', CombinedEngineer()),  # Feature engineering\n",
    "                ('scaler', StandardScaler()),  # scaling\n",
    "                ('smote', SMOTETransformer(sampling_strategy='auto', random_state=42)),  # SMOTE\n",
    "                ('classifier', model)  # Classifier\n",
    "            ])\n",
    "        else:\n",
    "            # FMS\n",
    "            pipeline = Pipeline([\n",
    "                ('feature_engineering', CombinedEngineer()),  # Feature engineering\n",
    "                ('scaler', MinMaxScaler()),  # scaling\n",
    "                ('smote', SMOTETransformer(sampling_strategy='auto', random_state=42)),  # SMOTE\n",
    "                ('classifier', model)  # Classifier\n",
    "            ])\n",
    "\n",
    "        # Fit and evaluate the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_val)\n",
    "\n",
    "        # Evaluation metrics\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        precision = precision_score(y_val, y_pred, pos_label=1)\n",
    "        recall = recall_score(y_val, y_pred, pos_label=1)\n",
    "        f1 = f1_score(y_val, y_pred, average='binary')\n",
    "        print(f\"Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "        # Balanced accuracy\n",
    "        balanced_acc = balanced_accuracy_score(y_val, y_pred)\n",
    "        print(f\"Balanced Accuracy: {balanced_acc:.3f}\")\n",
    "\n",
    "        # MCC\n",
    "        mcc = matthews_corrcoef(y_val, y_pred)\n",
    "        \n",
    "        # PR-AUC\n",
    "        y_pred_proba = pipeline.predict_proba(X_val)\n",
    "\n",
    "\n",
    "        # ROC-AUC for both classes (Class 0 and Class 1)\n",
    "        roc_auc_0 = roc_auc_score(y_val, y_pred_proba[:, 0])  # ROC-AUC for Class 0 (majority class)\n",
    "        roc_auc_1 = roc_auc_score(y_val, y_pred_proba[:, 1])  # ROC-AUC for Class 1 (minority class)\n",
    "\n",
    "        # PR-AUC for both classes\n",
    "        precision_0, recall_0, _ = precision_recall_curve(y_val, y_pred_proba[:, 0])  # For Class 0\n",
    "        pr_auc_0 = auc(recall_0, precision_0)\n",
    "\n",
    "        precision_1, recall_1, _ = precision_recall_curve(y_val, y_pred_proba[:, 1])  # For Class 1\n",
    "        pr_auc_1 = auc(recall_1, precision_1)\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df_probs = pd.DataFrame(y_pred_proba, columns=[f\"{name}_prob_{i}\" for i in range(y_pred_proba.shape[1])])\n",
    "\n",
    "        # Add to the main DataFrame\n",
    "        prob_df = pd.concat([prob_df, df_probs], axis=1)\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": f\"{name}_{test}\",\n",
    "            \"Accuracy\": f\"{accuracy:.4f}\",\n",
    "            \"Precision\": f\"{precision:.4f}\",\n",
    "            \"Recall\": f\"{recall:.4f}\",\n",
    "            \"F1 Score\": f\"{f1:.4f}\",\n",
    "            \"Balanced Accuracy\": f\"{balanced_acc:.4f}\",\n",
    "            \"MCC\": f\"{mcc:.4f}\",\n",
    "            \"PR-AUC_0\": f\"{pr_auc_0:.4f}\",\n",
    "            \"PR-AUC_1\": f\"{pr_auc_1:.4f}\",\n",
    "            \"ROC-AUC_0\": f\"{roc_auc_0:.4f}\",\n",
    "            \"ROC-AUC_1\": f\"{roc_auc_1:.4f}\"\n",
    "        })\n",
    "\n",
    "prob_df.to_csv(\"b2_model_probabilities.csv\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df[\"Actual\"] = y_val.values\n",
    "prob_df.to_csv(\"b2_model_probabilities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
=======
   "execution_count": 29,
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Evaluation Results ===\n",
      "      Model Accuracy Precision  Recall F1 Score Balanced Accuracy     MCC  \\\n",
<<<<<<< HEAD
      "5    AB_FMS   0.7309    0.1651  0.2552   0.2005            0.5293  0.0493   \n",
      "13   AB_FSS   0.7329    0.1567  0.2328   0.1873            0.5210  0.0357   \n",
      "21    AB_SS   0.5372    0.1743  0.6694   0.2766            0.5932  0.1263   \n",
      "3    DT_FMS   0.8021    0.2567  0.2623   0.2595            0.5733  0.1453   \n",
      "11   DT_FSS   0.7859    0.2569  0.3271   0.2877            0.5915  0.1656   \n",
      "19    DT_SS   0.5372    0.1743  0.6694   0.2766            0.5932  0.1263   \n",
      "2   KNN_FMS   0.7656    0.2083  0.2761   0.2375            0.5581  0.1036   \n",
      "10  KNN_FSS   0.7594    0.2077  0.2913   0.2425            0.5610  0.1063   \n",
      "18   KNN_SS   0.8678    0.0000  0.0000   0.0000            0.5000  0.0000   \n",
      "0    LR_FMS   0.6685    0.2370  0.6789   0.3513            0.6729  0.2415   \n",
      "8    LR_FSS   0.6564    0.2364  0.7172   0.3556            0.6822  0.2518   \n",
      "16    LR_SS   0.6807    0.1465  0.2931   0.1953            0.5164  0.0252   \n",
      "7    NB_FMS   0.5443    0.2162  0.9318   0.3509            0.7085  0.2853   \n",
      "15   NB_FSS   0.5483    0.2172  0.9280   0.3520            0.7092  0.2859   \n",
      "23    NB_SS   0.7966    0.2235  0.2177   0.2206            0.5512  0.1036   \n",
      "1    NN_FMS   0.7572    0.1647  0.2055   0.1829            0.5234  0.0427   \n",
      "9    NN_FSS   0.7937    0.1814  0.1595   0.1697            0.5249  0.0526   \n",
      "17    NN_SS   0.5372    0.1743  0.6694   0.2766            0.5932  0.1263   \n",
      "4    RF_FMS   0.8440    0.3357  0.1844   0.2380            0.5644  0.1681   \n",
      "12   RF_FSS   0.8423    0.3166  0.1663   0.2181            0.5558  0.1487   \n",
      "20    RF_SS   0.5372    0.1743  0.6694   0.2766            0.5932  0.1263   \n",
      "6   XGB_FMS   0.6488    0.2538  0.8536   0.3912            0.7356  0.3212   \n",
      "14  XGB_FSS   0.6359    0.2502  0.8783   0.3894            0.7386  0.3242   \n",
      "22   XGB_SS   0.5372    0.1743  0.6694   0.2766            0.5932  0.1263   \n",
      "\n",
      "   PR-AUC_0 PR-AUC_1 ROC-AUC_0 ROC-AUC_1  \n",
      "5    0.0897   0.1988    0.3149    0.6851  \n",
      "13   0.0883   0.2024    0.3002    0.6998  \n",
      "21   0.1347   0.2735    0.3804    0.6196  \n",
      "3    0.4420   0.3082    0.4264    0.5736  \n",
      "11   0.4110   0.3362    0.4084    0.5916  \n",
      "19   0.1347   0.2735    0.3804    0.6196  \n",
      "2    0.3511   0.2168    0.4135    0.5865  \n",
      "10   0.3241   0.2254    0.3987    0.6013  \n",
      "18   0.4646   0.2550    0.4454    0.5546  \n",
      "0    0.0847   0.2317    0.2649    0.7351  \n",
      "8    0.0844   0.2353    0.2624    0.7376  \n",
      "16   0.3341   0.2196    0.5059    0.4941  \n",
      "7    0.0904   0.2428    0.2618    0.7387  \n",
      "15   0.0906   0.2440    0.2617    0.7388  \n",
      "23   0.2259   0.2339    0.4317    0.5683  \n",
      "1    0.1823   0.1419    0.6043    0.3957  \n",
      "9    0.1898   0.1340    0.5980    0.4020  \n",
      "17   0.1347   0.2732    0.3805    0.6195  \n",
      "4    0.0790   0.3331    0.1914    0.8086  \n",
      "12   0.0794   0.3206    0.1956    0.8044  \n",
      "20   0.1347   0.2735    0.3804    0.6196  \n",
      "6    0.0780   0.3544    0.1892    0.8108  \n",
      "14   0.0779   0.3663    0.1874    0.8126  \n",
      "22   0.1347   0.2735    0.3804    0.6196  \n"
=======
      "5   AB_FESS   0.7240    0.8944  0.7733   0.8294            0.5870  0.1361   \n",
      "3   DT_FESS   0.7923    0.8852  0.8740   0.8796            0.5651  0.1258   \n",
      "2  KNN_FESS   0.7294    0.8976  0.7768   0.8328            0.5975  0.1528   \n",
      "0   LR_FESS   0.5575    0.9720  0.5046   0.6643            0.7045  0.2785   \n",
      "7   NB_FESS   0.5784    0.9588  0.5372   0.6886            0.6929  0.2615   \n",
      "1   NN_FESS   0.6923    0.9205  0.7065   0.7994            0.6529  0.2196   \n",
      "4   RF_FESS   0.8370    0.8800  0.9405   0.9092            0.5492  0.1285   \n",
      "6  XGB_FESS   0.6260    0.9722  0.5857   0.7310            0.7380  0.3228   \n",
      "\n",
      "  PR-AUC_0 PR-AUC_1 ROC-AUC_0 ROC-AUC_1  \n",
      "5   0.8055   0.9514    0.2743    0.7257  \n",
      "3   0.8240   0.9343    0.4350    0.5650  \n",
      "2   0.8165   0.9343    0.3565    0.6435  \n",
      "0   0.7851   0.9550    0.2463    0.7537  \n",
      "7   0.7900   0.9524    0.2589    0.7411  \n",
      "1   0.8034   0.9482    0.2761    0.7239  \n",
      "4   0.7790   0.9603    0.2297    0.7703  \n",
      "6   0.7641   0.9656    0.1984    0.8016  \n"
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
     ]
    }
   ],
   "source": [
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort the results by \"Model\" alphabetically\n",
    "results_df = results_df.sort_values(by=\"Model\")\n",
    "\n",
    "# Display the results table\n",
    "print(\"\\n=== Model Evaluation Results ===\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 30,
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>MCC</th>\n",
       "      <th>PR-AUC_0</th>\n",
       "      <th>PR-AUC_1</th>\n",
       "      <th>ROC-AUC_0</th>\n",
       "      <th>ROC-AUC_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
<<<<<<< HEAD
       "      <td>AB_FMS</td>\n",
       "      <td>0.7309</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.2005</td>\n",
       "      <td>0.5293</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.3149</td>\n",
       "      <td>0.6851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AB_FSS</td>\n",
       "      <td>0.7329</td>\n",
       "      <td>0.1567</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.1873</td>\n",
       "      <td>0.5210</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>0.2024</td>\n",
       "      <td>0.3002</td>\n",
       "      <td>0.6998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AB_SS</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.1743</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>0.2766</td>\n",
       "      <td>0.5932</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.6196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT_FMS</td>\n",
       "      <td>0.8021</td>\n",
       "      <td>0.2567</td>\n",
       "      <td>0.2623</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.5733</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.4420</td>\n",
       "      <td>0.3082</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.5736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DT_FSS</td>\n",
       "      <td>0.7859</td>\n",
       "      <td>0.2569</td>\n",
       "      <td>0.3271</td>\n",
       "      <td>0.2877</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>0.1656</td>\n",
       "      <td>0.4110</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>0.4084</td>\n",
       "      <td>0.5916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DT_SS</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.1743</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>0.2766</td>\n",
       "      <td>0.5932</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.6196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN_FMS</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.2761</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.5581</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.3511</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.4135</td>\n",
       "      <td>0.5865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNN_FSS</td>\n",
       "      <td>0.7594</td>\n",
       "      <td>0.2077</td>\n",
       "      <td>0.2913</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.5610</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.3241</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>0.3987</td>\n",
       "      <td>0.6013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KNN_SS</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4646</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>0.4454</td>\n",
       "      <td>0.5546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_FMS</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.3513</td>\n",
       "      <td>0.6729</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.2649</td>\n",
       "      <td>0.7351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR_FSS</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>0.3556</td>\n",
       "      <td>0.6822</td>\n",
       "      <td>0.2518</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.2624</td>\n",
       "      <td>0.7376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LR_SS</td>\n",
       "      <td>0.6807</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2931</td>\n",
       "      <td>0.1953</td>\n",
       "      <td>0.5164</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.3341</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.4941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB_FMS</td>\n",
       "      <td>0.5443</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.9318</td>\n",
       "      <td>0.3509</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>0.2853</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>0.2618</td>\n",
       "      <td>0.7387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NB_FSS</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.9280</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.7092</td>\n",
       "      <td>0.2859</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.2617</td>\n",
       "      <td>0.7388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NB_SS</td>\n",
       "      <td>0.7966</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>0.5512</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.2259</td>\n",
       "      <td>0.2339</td>\n",
       "      <td>0.4317</td>\n",
       "      <td>0.5683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN_FMS</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.1647</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.1829</td>\n",
       "      <td>0.5234</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.1823</td>\n",
       "      <td>0.1419</td>\n",
       "      <td>0.6043</td>\n",
       "      <td>0.3957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NN_FSS</td>\n",
       "      <td>0.7937</td>\n",
       "      <td>0.1814</td>\n",
       "      <td>0.1595</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.5980</td>\n",
       "      <td>0.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NN_SS</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.1743</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>0.2766</td>\n",
       "      <td>0.5932</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.3805</td>\n",
       "      <td>0.6195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_FMS</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.3357</td>\n",
       "      <td>0.1844</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>0.5644</td>\n",
       "      <td>0.1681</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.1914</td>\n",
       "      <td>0.8086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RF_FSS</td>\n",
       "      <td>0.8423</td>\n",
       "      <td>0.3166</td>\n",
       "      <td>0.1663</td>\n",
       "      <td>0.2181</td>\n",
       "      <td>0.5558</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.3206</td>\n",
       "      <td>0.1956</td>\n",
       "      <td>0.8044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RF_SS</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.1743</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>0.2766</td>\n",
       "      <td>0.5932</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.6196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB_FMS</td>\n",
       "      <td>0.6488</td>\n",
       "      <td>0.2538</td>\n",
       "      <td>0.8536</td>\n",
       "      <td>0.3912</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.3212</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>0.3544</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.8108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGB_FSS</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>0.2502</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>0.3894</td>\n",
       "      <td>0.7386</td>\n",
       "      <td>0.3242</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>0.3663</td>\n",
       "      <td>0.1874</td>\n",
       "      <td>0.8126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGB_SS</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.1743</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>0.2766</td>\n",
       "      <td>0.5932</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.6196</td>\n",
=======
       "      <td>AB_FESS</td>\n",
       "      <td>0.7240</td>\n",
       "      <td>0.8944</td>\n",
       "      <td>0.7733</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.8055</td>\n",
       "      <td>0.9514</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.7257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT_FESS</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.5651</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>0.9343</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>0.5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN_FESS</td>\n",
       "      <td>0.7294</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.7768</td>\n",
       "      <td>0.8328</td>\n",
       "      <td>0.5975</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.8165</td>\n",
       "      <td>0.9343</td>\n",
       "      <td>0.3565</td>\n",
       "      <td>0.6435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_FESS</td>\n",
       "      <td>0.5575</td>\n",
       "      <td>0.9720</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.6643</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.2785</td>\n",
       "      <td>0.7851</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>0.7537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB_FESS</td>\n",
       "      <td>0.5784</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.2615</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>0.7411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN_FESS</td>\n",
       "      <td>0.6923</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.7065</td>\n",
       "      <td>0.7994</td>\n",
       "      <td>0.6529</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.8034</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.2761</td>\n",
       "      <td>0.7239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_FESS</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>0.7790</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>0.2297</td>\n",
       "      <td>0.7703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB_FESS</td>\n",
       "      <td>0.6260</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>0.3228</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.8016</td>\n",
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model Accuracy Precision  Recall F1 Score Balanced Accuracy     MCC  \\\n",
<<<<<<< HEAD
       "5    AB_FMS   0.7309    0.1651  0.2552   0.2005            0.5293  0.0493   \n",
       "13   AB_FSS   0.7329    0.1567  0.2328   0.1873            0.5210  0.0357   \n",
       "21    AB_SS   0.5372    0.1743  0.6694   0.2766            0.5932  0.1263   \n",
       "3    DT_FMS   0.8021    0.2567  0.2623   0.2595            0.5733  0.1453   \n",
       "11   DT_FSS   0.7859    0.2569  0.3271   0.2877            0.5915  0.1656   \n",
       "19    DT_SS   0.5372    0.1743  0.6694   0.2766            0.5932  0.1263   \n",
       "2   KNN_FMS   0.7656    0.2083  0.2761   0.2375            0.5581  0.1036   \n",
       "10  KNN_FSS   0.7594    0.2077  0.2913   0.2425            0.5610  0.1063   \n",
       "18   KNN_SS   0.8678    0.0000  0.0000   0.0000            0.5000  0.0000   \n",
       "0    LR_FMS   0.6685    0.2370  0.6789   0.3513            0.6729  0.2415   \n",
       "8    LR_FSS   0.6564    0.2364  0.7172   0.3556            0.6822  0.2518   \n",
       "16    LR_SS   0.6807    0.1465  0.2931   0.1953            0.5164  0.0252   \n",
       "7    NB_FMS   0.5443    0.2162  0.9318   0.3509            0.7085  0.2853   \n",
       "15   NB_FSS   0.5483    0.2172  0.9280   0.3520            0.7092  0.2859   \n",
       "23    NB_SS   0.7966    0.2235  0.2177   0.2206            0.5512  0.1036   \n",
       "1    NN_FMS   0.7572    0.1647  0.2055   0.1829            0.5234  0.0427   \n",
       "9    NN_FSS   0.7937    0.1814  0.1595   0.1697            0.5249  0.0526   \n",
       "17    NN_SS   0.5372    0.1743  0.6694   0.2766            0.5932  0.1263   \n",
       "4    RF_FMS   0.8440    0.3357  0.1844   0.2380            0.5644  0.1681   \n",
       "12   RF_FSS   0.8423    0.3166  0.1663   0.2181            0.5558  0.1487   \n",
       "20    RF_SS   0.5372    0.1743  0.6694   0.2766            0.5932  0.1263   \n",
       "6   XGB_FMS   0.6488    0.2538  0.8536   0.3912            0.7356  0.3212   \n",
       "14  XGB_FSS   0.6359    0.2502  0.8783   0.3894            0.7386  0.3242   \n",
       "22   XGB_SS   0.5372    0.1743  0.6694   0.2766            0.5932  0.1263   \n",
       "\n",
       "   PR-AUC_0 PR-AUC_1 ROC-AUC_0 ROC-AUC_1  \n",
       "5    0.0897   0.1988    0.3149    0.6851  \n",
       "13   0.0883   0.2024    0.3002    0.6998  \n",
       "21   0.1347   0.2735    0.3804    0.6196  \n",
       "3    0.4420   0.3082    0.4264    0.5736  \n",
       "11   0.4110   0.3362    0.4084    0.5916  \n",
       "19   0.1347   0.2735    0.3804    0.6196  \n",
       "2    0.3511   0.2168    0.4135    0.5865  \n",
       "10   0.3241   0.2254    0.3987    0.6013  \n",
       "18   0.4646   0.2550    0.4454    0.5546  \n",
       "0    0.0847   0.2317    0.2649    0.7351  \n",
       "8    0.0844   0.2353    0.2624    0.7376  \n",
       "16   0.3341   0.2196    0.5059    0.4941  \n",
       "7    0.0904   0.2428    0.2618    0.7387  \n",
       "15   0.0906   0.2440    0.2617    0.7388  \n",
       "23   0.2259   0.2339    0.4317    0.5683  \n",
       "1    0.1823   0.1419    0.6043    0.3957  \n",
       "9    0.1898   0.1340    0.5980    0.4020  \n",
       "17   0.1347   0.2732    0.3805    0.6195  \n",
       "4    0.0790   0.3331    0.1914    0.8086  \n",
       "12   0.0794   0.3206    0.1956    0.8044  \n",
       "20   0.1347   0.2735    0.3804    0.6196  \n",
       "6    0.0780   0.3544    0.1892    0.8108  \n",
       "14   0.0779   0.3663    0.1874    0.8126  \n",
       "22   0.1347   0.2735    0.3804    0.6196  "
      ]
     },
     "execution_count": 16,
=======
       "5   AB_FESS   0.7240    0.8944  0.7733   0.8294            0.5870  0.1361   \n",
       "3   DT_FESS   0.7923    0.8852  0.8740   0.8796            0.5651  0.1258   \n",
       "2  KNN_FESS   0.7294    0.8976  0.7768   0.8328            0.5975  0.1528   \n",
       "0   LR_FESS   0.5575    0.9720  0.5046   0.6643            0.7045  0.2785   \n",
       "7   NB_FESS   0.5784    0.9588  0.5372   0.6886            0.6929  0.2615   \n",
       "1   NN_FESS   0.6923    0.9205  0.7065   0.7994            0.6529  0.2196   \n",
       "4   RF_FESS   0.8370    0.8800  0.9405   0.9092            0.5492  0.1285   \n",
       "6  XGB_FESS   0.6260    0.9722  0.5857   0.7310            0.7380  0.3228   \n",
       "\n",
       "  PR-AUC_0 PR-AUC_1 ROC-AUC_0 ROC-AUC_1  \n",
       "5   0.8055   0.9514    0.2743    0.7257  \n",
       "3   0.8240   0.9343    0.4350    0.5650  \n",
       "2   0.8165   0.9343    0.3565    0.6435  \n",
       "0   0.7851   0.9550    0.2463    0.7537  \n",
       "7   0.7900   0.9524    0.2589    0.7411  \n",
       "1   0.8034   0.9482    0.2761    0.7239  \n",
       "4   0.7790   0.9603    0.2297    0.7703  \n",
       "6   0.7641   0.9656    0.1984    0.8016  "
      ]
     },
     "execution_count": 30,
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"b2_pipeline_comparison_results.csv\")"
=======
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"b2_results_RFE.csv\")"
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 2. Check the transformed data at each step\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# For training data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# X_engineered = feature_engineering_step.transform(X_train)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m scaler_step\u001b[38;5;241m.\u001b[39mtransform(X_engineered)\n\u001b[1;32m---> 12\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m \u001b[43msmote_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 3. Check shapes to understand SMOTE's effect\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal X_train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cryst\\VSCode\\repos\\INF2008_YelpZip\\0z_contextual\\SmoteTransformer.py:17\u001b[0m, in \u001b[0;36mSMOTETransformer.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Apply SMOTE only when both X and y are available (training data).\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 17\u001b[0m     X_resampled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_resampled\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[1;32mc:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:202\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:105\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m     99\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    103\u001b[0m )\n\u001b[1;32m--> 105\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    109\u001b[0m )\n\u001b[0;32m    111\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32mc:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:369\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    367\u001b[0m     X_resampled \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mvstack(X_resampled, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 369\u001b[0m     X_resampled \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_resampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m y_resampled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack(y_resampled)\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_resampled, y_resampled\n",
      "File \u001b[1;32mc:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
   "source": [
    "# 1. Access individual steps in the pipeline\n",
    "# feature_engineering_step = pipeline.named_steps['feature_engineering']\n",
    "scaler_step = pipeline.named_steps['scaler']\n",
    "smote_step = pipeline.named_steps['smote']\n",
    "classifier_step = pipeline.named_steps['classifier']\n",
    "\n",
    "X_engineered = X_train\n",
    "# 2. Check the transformed data at each step\n",
    "# For training data\n",
    "# X_engineered = feature_engineering_step.transform(X_train)\n",
    "X_scaled = scaler_step.transform(X_engineered)\n",
    "X_resampled, y_resampled = smote_step.fit_resample(X_scaled, y_train)\n",
    "\n",
    "# 3. Check shapes to understand SMOTE's effect\n",
    "print(f\"Original X_train shape: {X_train.shape}\")\n",
    "print(f\"After engineering: {X_engineered.shape}\")\n",
    "print(f\"After scaling: {X_scaled.shape}\")\n",
    "print(f\"After SMOTE: {X_resampled.shape}, y_resampled: {y_resampled.shape}\")\n",
    "\n",
    "# 4. Compare class distributions\n",
    "from collections import Counter\n",
    "print(f\"Original class distribution: {Counter(y_train)}\")\n",
    "print(f\"Resampled class distribution: {Counter(y_resampled)}\")\n",
    "\n",
    "# 5. Extract feature importances (if classifier supports it)\n",
    "if hasattr(classifier_step, 'feature_importances_'):\n",
    "    importances = classifier_step.feature_importances_\n",
    "    print(importances)\n",
    "\n",
    "    # Print top features\n",
    "elif hasattr(classifier_step, 'coef_'):\n",
    "    importances = classifier_step.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: LR ===\n",
      "Accuracy: 0.662, Precision: 0.233, Recall: 0.678, F1: 0.346\n",
      "Balanced Accuracy: 0.669\n",
      "=== Model: NN ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.806, Precision: 0.195, Recall: 0.144, F1: 0.163\n",
      "Balanced Accuracy: 0.525\n",
      "=== Model: KNN ===\n",
      "Accuracy: 0.752, Precision: 0.210, Recall: 0.316, F1: 0.252\n",
      "Balanced Accuracy: 0.567\n",
      "=== Model: DT ===\n",
      "Accuracy: 0.786, Precision: 0.244, Recall: 0.293, F1: 0.263\n",
      "Balanced Accuracy: 0.577\n",
      "=== Model: RF ===\n",
      "Accuracy: 0.841, Precision: 0.310, Recall: 0.168, F1: 0.217\n",
      "Balanced Accuracy: 0.555\n",
      "=== Model: AB ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cryst\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.733, Precision: 0.148, Recall: 0.214, F1: 0.175\n",
      "Balanced Accuracy: 0.513\n",
      "=== Model: XGB ===\n",
      "Accuracy: 0.673, Precision: 0.249, Recall: 0.725, F1: 0.361\n",
      "Balanced Accuracy: 0.695\n",
      "=== Model: NB ===\n",
      "Accuracy: 0.543, Precision: 0.215, Recall: 0.927, F1: 0.349\n",
      "Balanced Accuracy: 0.706\n"
     ]
    }
   ],
   "source": [
    "# Combine the train sets for auto-splitting during K-fold\n",
    "X_train_kf = pd.concat([X_train, X_val], ignore_index=True)\n",
    "y_train_kf = pd.concat([y_train, y_val], ignore_index=True)\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from FeatureEngineer import CombinedEngineer\n",
    "from SmoteTransformer import SMOTETransformer\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    balanced_accuracy_score, matthews_corrcoef, roc_auc_score, precision_recall_curve, auc,\n",
    "    make_scorer\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "prob_df = pd.DataFrame()\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"=== Model: {name} ===\")\n",
    "\n",
    "    # Define pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('feature_engineering', CombinedEngineer()),  # Feature engineering\n",
    "        ('scaler', StandardScaler()),  # Scaling\n",
    "        ('smote', SMOTETransformer(sampling_strategy='auto', random_state=42)),  # SMOTE\n",
    "        ('classifier', model)  # Classifier\n",
    "    ])\n",
    "\n",
    "    # Define scoring metrics\n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'f1': 'f1',\n",
    "        'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
    "        'mcc': make_scorer(matthews_corrcoef)\n",
    "    }\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_results = cross_validate(pipeline, X_train_kf, y_train_kf, cv=cv, scoring=scoring, return_train_score=False)\n",
    "\n",
    "    # Get predicted probabilities for PR-AUC & ROC-AUC\n",
    "    y_pred_proba = cross_val_predict(pipeline, X_train_kf, y_train_kf, cv=cv, method=\"predict_proba\")\n",
    "\n",
    "    # Compute additional metrics\n",
    "    roc_auc_0 = roc_auc_score(y_train_kf, y_pred_proba[:, 0])\n",
    "    roc_auc_1 = roc_auc_score(y_train_kf, y_pred_proba[:, 1])\n",
    "\n",
    "    precision_0, recall_0, _ = precision_recall_curve(y_train_kf, y_pred_proba[:, 0])\n",
    "    pr_auc_0 = auc(recall_0, precision_0)\n",
    "\n",
    "    precision_1, recall_1, _ = precision_recall_curve(y_train_kf, y_pred_proba[:, 1])\n",
    "    pr_auc_1 = auc(recall_1, precision_1)\n",
    "\n",
    "    print(f\"Accuracy: {np.mean(cv_results['test_accuracy']):.3f}, Precision: {np.mean(cv_results['test_precision']):.3f}, Recall: {np.mean(cv_results['test_recall']):.3f}, F1: {np.mean(cv_results['test_f1']):.3f}\")\n",
    "    print(f\"Balanced Accuracy: {np.mean(cv_results['test_balanced_accuracy']):.3f}\")\n",
    "    # Store metrics\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": f\"{np.mean(cv_results['test_accuracy']):.4f} Â± {np.std(cv_results['test_accuracy']):.4f}\",\n",
    "        \"Precision\": f\"{np.mean(cv_results['test_precision']):.4f} Â± {np.std(cv_results['test_precision']):.4f}\",\n",
    "        \"Recall\": f\"{np.mean(cv_results['test_recall']):.4f} Â± {np.std(cv_results['test_recall']):.4f}\",\n",
    "        \"F1 Score\": f\"{np.mean(cv_results['test_f1']):.4f} Â± {np.std(cv_results['test_f1']):.4f}\",\n",
    "        \"Balanced Accuracy\": f\"{np.mean(cv_results['test_balanced_accuracy']):.4f} Â± {np.std(cv_results['test_balanced_accuracy']):.4f}\",\n",
    "        \"MCC\": f\"{np.mean(cv_results['test_mcc']):.4f} Â± {np.std(cv_results['test_mcc']):.4f}\",\n",
    "        \"PR-AUC_0\": f\"{pr_auc_0:.4f}\",\n",
    "        \"PR-AUC_1\": f\"{pr_auc_1:.4f}\",\n",
    "        \"ROC-AUC_0\": f\"{roc_auc_0:.4f}\",\n",
    "        \"ROC-AUC_1\": f\"{roc_auc_1:.4f}\"\n",
    "    })\n",
    "\n",
    "    # Store probabilities for stacking\n",
    "    df_probs = pd.DataFrame(y_pred_proba, columns=[f\"{name}_prob_{i}\" for i in range(y_pred_proba.shape[1])])\n",
    "    prob_df = pd.concat([prob_df, df_probs], axis=1)\n",
    "\n",
    "# Save probabilities for stacking\n",
    "prob_df.to_csv(\"b2_model_probabilities_Kf.csv\")\n",
    "\n",
    "# Save results\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"b2_cross_validation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Â± symbol and the standard deviation\n",
    "df_results_cleaned = df_results.copy()\n",
    "for col in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Balanced Accuracy', 'MCC']:\n",
    "    df_results_cleaned[col] = df_results_cleaned[col].str.split(' Â± ').str[0]\n",
    "\n",
    "df_results_cleaned.to_csv(\"b2_cross_validation_results_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
>>>>>>> 9f98ec006b15b66eec571b44739046af5a2d046c
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# checking versions (sync with kaggle if using)\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "print(\"Python Version:\", sys.version)\n",
    "print(\"NumPy Version:\", np.__version__)\n",
    "print(\"Pandas Version:\", pd.__version__)\n",
    "print(\"Scikit-Learn Version:\", sklearn.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
